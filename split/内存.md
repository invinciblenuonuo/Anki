# 内存

## 内存模型 data bss heap stack

- Flash = Code + RO-data + RW-data
- RAM = RW-data + ZI-data

内存四区：代码区，全局区，堆区，栈区

| 地址   | 区域             | 内容                                                       | 存放位置 | 举例                                    |
| ------ | ---------------- | ---------------------------------------------------------- | -------- | --------------------------------------- |
| 0x0000 | .text 代码段     | 编译后的机器码                                             | Flash    | \#define ro_def 0x11111111UL            |
|        | .ROdata          | 只读常量                                                   | Flash    | const uint32_t ro_var = 0x22222222;     |
|        | .RWdata 已初始化 | 静态变量、全局变量，启动时从Flash读取已初始化数据搬运到RAM | RAM      | int global_var= 123;  static int c = 0; |
|        | .bss 未初始化    | 全局变量，启动时，自动初始化为0                            | RAM      | int global_var;                         |
|        | .heap  堆        | 动态内存分配，程序员手动开辟释放，向↓增长                  |          |                                         |
|        | ----------       |                                                            |          |                                         |
| 0xFFFF | .stack 栈        | 函数局部变量，由编译器开辟释放，向↑增长                    |          |                                         |



初始化过程：数据一开始都存储与ROM中，其中包含RO DATA（常量）、text（代码）、RW DATA（先存储于flash，上电后搬运到RAM）。RAM：加载来自于ROM 的 RW DATA，随后依据启动文件初始化ZI DATA为0



## 数组下标越界

```c
int arr[5];

arr[-1];  // 可能可以正常执行
arr[5];  // 一定报错
```

由于函数栈的增长方向为高地址->低地址，高地址处存放函数返回信息和比数组先存入的信息，并且数组的存储顺序为下标小的元素在低地址，因此往高地址越界时会改写原本栈中的数据，往低地址越界修改的是空的未使用的栈，可能不出问题。

解决方案：利用assert和迭代器来避免



## MCU采用 XIP（eXecute In Place）的方式在 Flash 中运行程序，而不是搬运到 RAM 中

1. 节省内存空间：MCU 往往具有较小的内存容量，特别是 RAM 的容量较有限。使用 XIP 可以避免将程序复制到 RAM 中造成内存空间的占用，从而节省了宝贵的 RAM 空间，可以将 RAM 用于其他需要快速存取的数据。
2. 成本优势：RAM 往往比 Flash 的价格更高，因此将程序直接运行在 Flash 中可以降低系统成本。在 MCU 中，Flash 往往是固化在芯片内部的，而 RAM 需要额外的外部芯片或部件支持，增加了系统的复杂性和成本。
3. 提高读取速度：Flash 存储器通常具有较快的访问速度，对于微控制器来说，执行程序时可能已经足够快。在 XIP 模式下，不需要将程序从 Flash 复制到 RAM，节省了在复制过程中的时间，可以直接在 Flash 中运行，加快了程序的启动时间和响应速度。
4. 适用于嵌入式系统：MCU 往往嵌入在一些资源受限、功耗要求较低的嵌入式系统中。使用 XIP 可以减少对外部 RAM 的需求，降低功耗，并且提高系统整体的稳定性和可靠性。

尽管 XIP 有以上的优势，它仍然存在一些限制和考虑因素，例如访问延迟较高、不适用于频繁写操作的场景等。因此在设计 MCU 的时候需要综合考虑具体的应用场景和需求来选择合适的存储方案。



## Linux栈一般多大

- Linux栈的大小可以在编译内核时进行配置，并且可以根据系统需求进行调整。栈的大小决定了每个线程的可用栈空间大小。
- 在大多数Linux系统上，默认的栈大小为8MB。但是，这个值并不是固定的，可以通过修改内核参数或使用特定的命令来改变栈的大小。



## 为什么栈从上往下（高地址->低地址）生长？

- 栈的生长方向：指的是入栈方向，从高地址向低地址生长叫做向下生长，或逆向生长。STM32的栈是向下生长
- 当需要分配新的栈帧时，栈指针将向较低的内存地址方向移动，为新的栈帧分配空间。而当不再需要某个栈帧时，栈指针会向较高的内存地址方向移动，释放该栈帧所占用的内存空间。



## 操作系统对内存管理的作用

- 内存分配与回收
- 采用虚拟内存进行扩容
- 负责逻辑地址到物理地址的转换
- 实现内存保护与隔离（应用间、内核隔离）



## 分页管理

定义：将内存分为大小相等的页框、进程也分为页框，OS将进程的页框一一对应放入内存

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230703161633033.png" alt="image-20230703161633033" style="zoom:50%;" />

在进程控制块PCB中存放页表，记录了进程页号和内存块号之间的对应关系

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230703162109683.png" alt="image-20230703162109683" style="zoom:67%;" />



## 逻辑地址到物理地址的转换

1. 依据逻辑地址，整除页面大小得到页号，余数为页内偏移量
2. 判断越界
3. 通过PCB中保存的页表查询该页存放在哪一块内存（逻辑内存地址）
4. 通过逻辑内存地址计算实际物理内存地址

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230703164233310.png" alt="image-20230703164233310" style="zoom: 50%;" />



## 缺页中断

为了使得页表不用常驻内存，将页表分为2级管理，1级页表存储页表索引，2级页表存储内存逻辑地址

当某些页面不在内存中但被访问到时发生缺页中断

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230703173202523.png" alt="image-20230703173202523" style="zoom:50%;" />



## 虚拟内存

将即将使用的数据装入内存，若内存满了，将不用的数据换入磁盘

第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。

 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。



## Nor Flash Nand Flash

NoR Flash中不仅可以存储数据，且可以取指运行(XIR)，也就是MCU给出地址，Nor可以直接返回指令交给MCU去执行，这样不用把指令拷贝到RAM里去执行；

NAND Flash仅可用于存储，取值时需要搬运到RAM中



## 堆和栈的区别

申请方式：stack：系统分配与回收（栈内存分配运算内置于处理器的指令集）；heap：程序员申请与释放

存储位置与方向：stack：高地址—》低地址；heap：低地址—》高地址

碎片问题：stack无碎片FIFO；heap存在内外碎片

存放内容：stack：函数返回地址、局部变量的值；heap：用户定义

栈的动态分配主要是malloc函数实现的，由编译器自动释放；堆只有动态分配用new实现，由程序员手动释放



## 内存碎片

内存碎片分为内碎片与外碎片

​		外碎片：还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。

​		内碎片：已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；（按固定大小分配给进程）

产生原因：分配较多不连续的空间后，剩余可用空间被孤立



## 内存对齐

1. **平台原因(移植)**：不是所有的硬件平台都能访问任意地址上的任意数据；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。
2. **性能原因**：为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。

如果一个变量的内存地址正好位于它长度的整数倍，他就被称做自然对齐。如果在 32 位的机器下， char 对齐值为1， short 为2， int，float为4，double 为 8

```c
struct asd1{
    char a;
    char b;
    short c;
    int d;
};//8字节
 
struct asd2{
    char a;
    short b;
    char c
    int d;
};//12字节
```

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20221210183108484.png" alt="image-20221210183108484" style="zoom:67%;" />

规则：按照`#pragma pack`指定的数值和这个数据成员自身长度中，比较小的那个进行（最后一个char也占用4Byte）

```c
#pragma pack(4)
struct asd3{
    char a;
    int b;
    short c;
    float d;
    char e;
};//20字节
#pragma pack()
 
#pragma pack(1)
struct asd4{
    char a;
    int b;
    short c;
    float d;
    char e;
};//12字节
#pragma pack()
```

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20221210184840436.png" alt="image-20221210184840436" style="zoom: 67%;" />







## malloc的底层实现

调用malloc时，去内存空闲链表内寻找可分配的空间，返回首地址指针

以RTT为例：内存管理方法可分为一、内存堆管理（小内存、slab大内存、多内存memheap）与二、内存池管理

一、内存堆管理`

​		小内存管理：从整块内存中通过链表寻找空闲内存块（逐一向后寻找匹配空间）

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/08smem_work.png" alt="小内存管理工作机制图" style="zoom: 80%;" />

​		slab：将整块内存分为多个不同大小的类别（对号入座）适合于大量的、细小的数据结构的内存申请的情况

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/08slab.png" alt="slab 内存分配结构图" style="zoom: 80%;" />

​		memheap：多个地址不连续内存，将其连接起来使用

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/08memheap.png" alt="memheap 处理多内存堆" style="zoom:80%;" />

二、内存池管理

​		内存池：类似slab，分配大块内存

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/08mempool_work.png" alt="内存池工作机制图" style="zoom:80%;" />

对比：

| 分配算法 | 优点               | 缺点                         | 使用场景       |
| -------- | ------------------ | ---------------------------- | -------------- |
| 内存堆   | 可分配任意大小内存 | 每次均需要查找、容易产生碎片 | 大量细小内存   |
| 内存池   | 分配高效           | 无法分配小内存               | 块设备大量数据 |



## 虚拟内存

通过地址转换，使得应用程序运行在连续内存上，且与内核隔离





## 程序的装入、静态链接、动态链接

一、绝对装入（编译时确定绝对地址）

- 再另一台内存不同的电脑上可能无法运行



二、静态重定位（保存相对地址）（读取时转换）

- 编译、链接后存放为逻辑地址，保存的都是相对于0地址的相对值
- 地址空间必须连续且读入内存时，对所有逻辑地址进行运算，转换为物理地址（读入时）



三、动态重定位（保存相对地址）（运行时转换）

- 程序读入内存后，并不直接计算物理地址，实际执行时才进行转换，将逻辑地址转换为物理地址（调用时）

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230701214310764.png" alt="image-20230701214310764" style="zoom: 50%;" />

<img src="https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230701214850436.png" alt="image-20230701214850436" style="zoom:67%;" />



## 页表

带有权限属性，放在物理内存中的，用来**记录虚拟内存页与物理页映射关系**的一张表

功能：（虚拟地址与物理地址转换）、（隔离各进程）、（各进程分配连续空间）、（权限管理RW）

|              | 一级页表                                                   | 多级页表                         | 快表                       |
| ------------ | ---------------------------------------------------------- | -------------------------------- | -------------------------- |
| 内存访问速度 | 2次（访问页表+访问数据）                                   | 多次（访问一级、二级后访问数据） | 用高速缓存存放常用的页表项 |
| 空间利用率   | 低，虚拟内存越大，页表越大，内存碎片化严重（页表数量限制） | 高，按需分配各级页表             | /                          |



## 在1G内存的计算机中能否malloc(1.2G)？

在操作系统上可以，malloc申请的是虚拟内存，而非实际硬件内存。在硬件上不行



## brk()与mmap()

在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk（C++）sbrk（C），mmap，munmap这些系统调用实现的

进程分配内存的方式有两种系统调用方式：brk与mmap

- brk是将数据段(.data)的最高地址指针_edata往高地址推（高地址释放后低地址才能释放，只适用于小内存分配，碎片多）
- mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存（可以单独释放，碎片少）

相同点：分配的都是虚拟内存，首次访问时发生缺页中断，操作系统再负责分配物理内存，随后建立映射关系

![watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXppc2hpag==,size_16,color_FFFFFF,t_70-16711754442818.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXppc2hpag==,size_16,color_FFFFFF,t_70-16711754442818.png)

![watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXppc2hpag==,size_16,color_FFFFFF,t_70.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXppc2hpag==,size_16,color_FFFFFF,t_70.png)

![watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXppc2hpag==,size_16,color_FFFFFF,t_70-16711754138065.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXppc2hpag==,size_16,color_FFFFFF,t_70-16711754138065.png)



## FLEX RAM

TCM : Tightly-Coupled Memory 紧密耦合内存 。ITCM用于指令，DTCM用于数据，**特点是跟内核速度一样**（400MHz），而片上RAM的速度基本都达不到这个速度（200MHz）。很多时候我们希望将需要实时性的程序和变量分别放在ITCM和DTCM里面执行，本章就是解决这个问题。

1. ITCM（指令紧耦合存储器）：
    - ITCM用于存储指令（程序代码），通常具有较低的访问延迟和较高的带宽，以提供快速和可预测的指令访问。
    - ITCM通常与处理器核心直接相连，使得指令可以快速地从该存储区加载，从而加快指令执行速度。
    - ITCM的容量相对较小，通常只能存储少量的指令代码。
2. DTCM（数据紧耦合存储器）：
    - DTCM用于存储数据，如变量、栈、堆等，具有较低的读写访问延迟和高带宽。
    - DTCM与处理器核心直接相连，以提供快速的数据访问，使得数据可以快速加载和存储，提高数据操作的效率。
    - DTCM的容量通常相对较小，只能存储有限量的数据。
3. OCRAM（片上随机访问存储器）：
    - OCRAM是一种通用的片上随机访问存储器，用于存储数据和指令。
    - OCRAM的容量通常比ITCM和DTCM更大，可以存储更多的数据和代码。
    - OCRAM的访问速度和带宽一般较低，但相对来说会比外部存储器的访问速度快。

三者之间的主要区别在于其设计目标和功能。ITCM主要用于存储指令代码，提供快速指令访问；DTCM主要用于存储数据，提供快速数据访问；OCRAM则是一种通用存储器，可以同时存储指令和数据，容量相对较大，但速度和带宽可能不如ITCM和DTCM。

![v2-7e91f17b7c3b5c6834f90cf00b2dfb7a_720w.webp](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/v2-7e91f17b7c3b5c6834f90cf00b2dfb7a_720w.webp)

大家都知道 RAM 是掉电易失的，这种加速的方法如何在量产产品中使用呢？实际上使用以上的方法，MDK 会将特定的函数编译到 ROM 当中，在每次启动的时候都会将 ROM 中指定的函数拷贝到 RAM 放中。

[【经验分享】STM32H7时间关键代码在ITCM执行的超简单方法 (stmicroelectronics.cn)](https://shequ.stmicroelectronics.cn/thread-632590-1-1.html)


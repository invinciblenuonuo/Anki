# 内存管理

## 1.RTOS内存管理

**heap_1~5中除了heap_3分配在堆上，其余算法在.bss段开辟静态空间进行管理。没有内存池，可以自己实现。**

```c
// 定义内存堆的大小
#define configTOTAL_HEAP_SIZE (8 * 1024) // 8KB

// 全局变量 "uc_heap" 的定义
static uint8_t ucHeap[configTOTAL_HEAP_SIZE];
uint8_t *ucHeap = ucHeap;
```

[FreeRTOS笔记（六）：五种内存管理详解_CodeDog_wang的博客-CSDN博客](https://blog.csdn.net/weixin_43952192/article/details/108189300)

| 类别   | 优点                 | 缺点                             |
| ------ | -------------------- | -------------------------------- |
| heap_1 | 时间确定             | 只分配，不回收                   |
| heap_2 | 最佳匹配             | 回收但不合并、时间不确定         |
| heap_3 | 使用标准malloc、free | 代码量大、线程不安全、时间不确定 |
| heap_4 | 最佳匹配、合并相邻   | 时间不确定                       |
| heap_5 | 支持多段不连续RAM    | 时间不确定                       |

1. **heap_1**

- 只分配不回收，不合并空闲区块

2. **heap_2**

- 使用最佳拟合算法分配
- 回收，但不合并，有碎片

3. **heap_3**

- 使用标准库malloc()和free()函数
- heap的大小由链接器配置定义（启动文件定义）

4. **heap_4**

- 使用best fit算法来分配内存
- 合并相邻的空闲内存块

![856ee0739f2c46798c2c3dc3c76ff4c8.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/856ee0739f2c46798c2c3dc3c76ff4c8.png)

5. **heap_5**

在heap_4的基础上，可以从多个独立的内存空间分配内存。

### heap4

[FreeRTOS系列-- heap_4.c内存管理分析_为成功找方法的博客-CSDN博客](https://blog.csdn.net/yuanlin725/article/details/115087718)

1. **内存块合并**：
   Heap4支持相邻空闲内存块的合并，这有助于减少内存碎片，提高内存利用率。
2. **最佳适配**：
   Heap4使用最佳适配（best-fit）算法来选择最适合的空闲内存块进行分配。它在所有空闲块中找到一个大小最接近且能满足请求的块，这有助于减少内存碎片。

**Heap4的工作原理**

1. **初始化**：
   在FreeRTOS启动时，Heap4会初始化内存管理区域。将整个**可用内存区域**标记为一个大的**空闲块**，并将其添加到**空闲块链表**中。

2. **内存分配**：
   当应用程序请求内存分配时，Heap4会**遍历空闲块链表**，找到一个大小最接近且能满足请求的空闲块。如果找到合适的块，Heap4会将该块**分割成已分配块和剩余空闲块，然后返回已分配块的指针**。

3. **内存释放**：
   当应用程序释放内存时，Heap4会将该内存块标记为空闲，并尝试**将其与相邻的空闲块合并，形成一个更大的空闲块**。然后，Heap4会将合并后的**空闲块添加到空闲块链表**中。



## 2.mpu

**MPU**（Memory Protection Unit）是一种**硬件设备**，用于增强嵌入式系统的安全性和稳定性，通过管理每个程序对内存的访问权限。它的主要功能是防止软件错误对系统操作产生不良影响，以及隔离不同程序之间的内存访问，保护系统免受恶意软件攻击。

**MPU：**通过MPU对存储器的某些区域进行属性设置，设置其对特权级/用户级开放，可读可写/只读/只写、禁止访问、全访问、支持/禁止CACHE、缓冲等等的属性，通过MPU管理存储器，不至于某块内存被非法访问、数据破坏、CACHE等等。



## 3.mmu

**简述处理器在读内存的过程中，CPU 核、cache、MMU 如何协同工作?画出 CPU 核、 cache、MMU 、内存之间的关系示意图。**
**MMU的作用：**现代操作系统采用虚拟内存管理，这需要MMU(内存管理单元)的支持。MMU就是负责**虚拟地址**(virtual address)转化成**物理地址**。

**用MMU的：**`cortex-A`  windowsMacOs、Linux、Android

**不用MMU的：**`cortex-M`  FreeRTOS、VxWorks、Ucos

**MMU工作过程：**如果 CPU 启用了 MMU，CPU内核发出的地址将被 MMU截获,这时候从 CPU到 MMU的地址称为虚拟地址，而 MMU将这个 VA 翻译成为 PA发到 CPU 芯片的外部地址引脚上，也就是将 VA 映射到 PA中。

![image-20240701182606182.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20240701182606182.png)

**注：TLB是一种cache**

## 4.cache

高速     中等速度   低速

CPU <------> Cache <-----> RAM

Cache，就是一种缓存机制，它位于CPU和DDR RAM之间，为CPU和DDR之间的读写提供一段内存缓冲区。cache读写速度要比DDR快不少。例如CPU要执行DDR里的指令，可以一次性的读一块区域的指令到cache里，下次就可以直接从cache里获取指令，而不用反复的去访问速度较慢的DDR。又例如，CPU要写一块数据到DDR里，它可以将数据快速地写到cache里，然后手动执行一条刷新cache的指令就可以将这片数据都更新到DDR里，或者干脆就不刷新，待cache到合适的时候，自己再将内容flush到DDR里。总之一句话，**cache的存在意义就是拉近CPU和DDR直接的性能差异，提高整个系统性能。**

Cache分为I-Cache（指令缓存）与D-Cache（数据缓存），使用LRU策略

![20210528111327990.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/20210528111327990.png)

cache是多级的，在一个系统中你可能会看到L1、L2、L3, 当然越靠近core就越小，也是越昂贵。

CPU接收到指令后，它会最先向CPU中的一级缓存（L1 Cache）去寻找相关的数据，然一级缓存是与CPU同频运行的，但是由于容量较小，所以不可能每次都**缓存命中**。这时CPU会继续向下一级的二级缓存（L2 Cache）寻找，同样的道理，当所需要的数据在二级缓存中也没有的话，会继续转向L3 Cache、内存(主存)和硬盘.

![20210528111327990 - 副本.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/20210528111327990%20-%20%E5%89%AF%E6%9C%AC.png)

### 不能使用cache的情况

1. CPU读取外设的内存数据，如果外设的数据本身会变，如网卡接收到外部数据，那么CPU如果连续2次读外设的操作相差时间很短，而且访问的是同样的地址，上次的内存数据还存在于cache当中，那么CPU第二次读取的可能还是第一次缓存在cache里数据。
2. CPU往外设写数据，如向串口控制器的内存空间写数据，如果CPU第1次写的数据还存在于cache当中，第2次又往同样的地址写数据，CPU可能就只更新了一下cache，由cache输出到串口的只有第2次的内容，第1次写的数据就丢失了。
3. 在嵌入式开发环境中，经常需要在PC端使用调试工具来通过直接查看内存的方式以确定某些事件的发生，如果定义一个全局变量来记录中断计数或者task循环次数等，这个变量如果定义为cache的，你会发现有时候系统明明是正常运行的，但是这个全局变量很长时间都不动一下。其实它的累加效果在cache里，因为没有人引用该变量，而长时间不会flush到DDR里
4. 考虑双cpu的运行环境(不是双核)。cpu1和cpu2共享一块ddr，它们都能访问,这块共享内存用于处理器之间的通信。cpu1在写完数据到后立刻给cpu2一个中断信号，通知cpu2去读这块内存，如果用cache的方法，cpu1可能把更新的内容只写到cache里，还没有被换出到ddr里，cpu2就已经跑去读，那么读到的并不是期望的数据。

![image-20230607151630997.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20230607151630997.png)



### 为何启动时关闭Cache

在嵌入式系统和某些应用程序中，启动时关闭指令缓存（Instruction Cache）和数据缓存（Data Cache）是一种常见的做法。以下是一些原因：

1. 避免缓存冲突：在启动阶段，代码和数据通常是从外部存储器（如闪存）加载到内部存储器（如RAM）中。由于这些加载过程往往涉及重复的读写操作，启动时关闭缓存可以防止缓存中的“旧”数据对加载过程产生冲突，确保正确加载并执行新的代码和数据。
2. 简化启动过程：在关闭缓存的情况下，处理器将直接从内存中读取指令和数据，而不依赖于缓存。这样可以避免额外的缓存管理开销，并简化启动代码的编写和调试过程。
3. 确保数据的一致性：某些应用程序要求数据在内存和外部设备之间保持一致。在关闭缓存的情况下，每次访问数据都将直接从内存取，确内存中的数据始终与外部设备保持一致，关闭存并不适用于所有应用场景，并且可能会对性能产生负面影响。在实际应用中，应根据具体的系统需求和性能要求来决定是否关闭缓存。



### 存储器层次结构与分类

![20210528110828244.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/20210528110828244.png)





4. 被替换。常见的替换策略包括最近最少使用**（LRU）**策略、随机替换和最不频繁使用（LFU）等。

**缓存的性能优化**

缓存的设计和优化对整个系统的性能有着显著的影响。设计者会考虑多种因素：

- **缓存的大小**：更大的缓存可以存储更多数据，减少缓存未命中的几率，但成本更高且可能增加访问延迟。
- **关联性**：缓存可以是直接映射、组相联或全相联。关联性越高，缓存命中率通常越高，但管理复杂性和成本也越大。
- **写策略**：包括写回（Write Back）和写通（Write Through）。写回策略中，数据仅在必要时更新到主内存；写通策略中，数据同时写入缓存和主内存。

通过这些方法，缓存有效地减少了CPU和主内存之间的速度差异，优化了计算机的运行效率。

在STM32F7微控制器中，开启Cache（包括指令缓存和数据缓存）是通过编程配置相关的系统寄存器来实现的。这通常在系统的初始化阶段进行，确保从启动开始就能够提升性能。以下是如何在STM32F7系列中开启Cache的基本步骤：

### 在stm32H7开启缓存cache

使用CMSIS函数来启用I-Cache和D-Cache。

```c
/* 使能 I-Cache */
SCB_EnableICache();

/* 使能 D-Cache */
SCB_EnableDCache();
```



## 5.堆和栈的区别

栈的动态分配主要是由编译器分配，由编译器自动释放；

堆只有动态分配用通过 `pvPortMalloc` 和 `vPortFree` 手动管理实现，由程序员手动释放

|          | 栈                                                     | 堆                                                           |
| -------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 申请方式 | 系统分配与回收（栈内存分配运算内置于处理器的指令集）； | 程序员申请与释放                                             |
| 方向     | 高地址—》低地址；                                      | 低地址—》高地址                                              |
| 碎片问题 | 无碎片FIFO；                                           | 存在内外碎片                                                 |
| 存放内容 | 函数返回地址、局部变量的值；                           | 用户定义                                                     |
| 分配方式 | 栈的动态分配主要是由编译器分配，由编译器自动释放；     | 堆只有动态分配用通过 `pvPortMalloc` 和 `vPortFree` 手动管理实现，由程序员手动释放 |
| 内存位置 | 位于芯片的 SRAM                                        | 位于芯片的 SRAM                                              |



## 6.Flash 、SRAM

|      | Flash                                | SRAM                                                         |
| ---- | ------------------------------------ | ------------------------------------------------------------ |
| 用途 | 存储程序代码、存储常量数据           | 存储运行时数据（局部变量、全局变量、堆栈（Stack）和动态内存分配（Heap））、缓冲区 |
| 特点 | 掉电保存、读写速度慢、可擦写，1024KB | 掉电丢失、读写速度快、192KB                                  |

在典型的 STM32 系统中，内存分布大致如下：

```diff
+------------------------+
|  .text (程序代码)      |
+------------------------+
|  .data (已初始化数据)  |
+------------------------+
|  .bss (未初始化数据)   |
+------------------------+
|  堆 (Heap)             |
+------------------------+
|  栈 (Stack)            |
+------------------------+
|  其他内存区域          |
+------------------------+
```



## 7.任务栈爆炸

**常见原因**

1. **任务栈分配不足**：
   - 每个任务在创建时都会分配一定的栈空间。如果任务执行过程中使用的栈超过了分配的大小，就会导致栈溢出。
2. **递归调用**：
   - 递归调用可能导致栈深度迅速增加，特别是没有退出条件或退出条件不充分的递归。
5. **嵌套中断**：
   - 中断服务程序（ISR）如果占用过多栈空间，也可能导致栈溢出，尤其是嵌套中断的情况。

### **定位问题**

1. **启用栈检查**：
   
   - FreeRTOS 提供了几个选项来检测栈溢出，可以在 `FreeRTOSConfig.h` 文件中配置：
     ```c
     #define configCHECK_FOR_STACK_OVERFLOW 1
     ```
   - 方案1：在调度时检查栈指针是否越界（任务保存有栈顶和栈大小信息，每次切换时检查栈指针是否越界）
   
     - 优点：检测较快
     - 缺点：对于任务运行时溢出，而切换前又恢复正常的情况无法检测
   
     方案2：在调度时检查栈末尾的16个字节是否发生改变（创建任务时初始化为特定字符，每次切换时判断是否被改写）
   
     - 优点：可检出几乎所有溢出
     - 缺点：检测较慢
   
2. **查看任务栈高水位线**：
   - 在调试过程中，可以使用 `uxTaskGetStackHighWaterMark()` 函数查看每个任务剩余的最小栈空间。
     ```c
     UBaseType_t uxHighWaterMark = uxTaskGetStackHighWaterMark(NULL);
     ```

**解决问题**

1. **增大任务栈大小**：
   
   - 在创建任务时，适当增加任务的栈大小：
     ```c
     xTaskCreate(TaskFunction, "TaskName", configMINIMAL_STACK_SIZE + extra_stack_size, NULL, tskIDLE_PRIORITY, NULL);
     ```
   
2. **优化代码**：
   - 减少递归深度，或改用迭代方式。
   - 避免在栈上分配大数组或大变量，可以将其改为全局变量或动态分配在堆上。

3. **简化中断服务程序**：
   
   - 确保 ISR 短小精悍，将复杂处理移到任务上下文中。
   
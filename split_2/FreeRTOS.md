# FreeRTOS 相关

## 1.FreeRTOS 任务调度的简要过程

**FreeRTOS 任务调度是指 FreeRTOS 内核根据任务的优先级和状态来决定何时运行哪个任务**。

[FreeRTOS深入教程（任务创建的深入和任务调度机制分析）_freertos教程-CSDN博客](https://blog.csdn.net/m0_49476241/article/details/133973941)

1. ***\*任务创建：\****在 FreeRTOS 中，通过调用 xTaskCreate() 或类似函数创建任务。
2. ***\*确定初始运行任务：\****FreeRTOS 在启动时会自动**启动空闲任务**，它负责管理系统中没有其他可运行任务时的情况。
3. ***\*调度器启动：\****调度器负责根据各个任务的优先级和状态来进行合适的上下文切换。然后SVC中断。
4. ***\*抢占式调度：\****FreeRTOS 使用基于优先级的抢占式调度算法。当更高优先级的就绪状态任务准备好运行时，当前正在运行的低优先级任务将被暂停，并且控制权转移到高优先级任务。
5. ***\*时间片轮转：\****当任务优先级相等时采用。操作系统为每个任务分配一个时间片，即预定义的时间量。在时间片轮转调度方式下，每个任务可以执行一个时间片，然后系统将控制权移交给下一个就绪的任务。**如果一个任务在其时间片结束前没有完成，系统会暂停该任务，将控制权交给下一个就绪的任务**。这种调度方式有助于确保任务之间的公平性，避免某些任务长时间占用处理器，同时允许多个任务分享处理时间。
6. ***\*任务A阻塞：\****调用OSDelay或者vTaskDelay阻塞。
7. ***\*保存任务A的上下文：\****`PendSV`中断用于执行上下文切换，被`SysTick`中断或`osdelay`主动出发触发，优先级最低。
8. ***\*选择下一个任务：\****`PendSV` 中断服务程序会调用 `vTaskSwitchContext` 函数。这个函数是 FreeRTOS 的核心调度函数，它负责选择下一个将要运行的任务，并更新当前任务控制块（TCB）指针 `pxCurrentTCB`。
9. ***\*恢复任务B的上下文：\****
10. ***\*延迟与阻塞：\****FreeRTOS 允许在等待事件发生或特定条件满足时使得一个或多个线程进入延迟或阻塞状态，并在条件满足后重新激活这些线程。

### 任务运行示例(时间片+优先级)

`configUSE_PREEMPTION`优先级抢占宏 `configUSE_TIME_SLICING`时间片轮询宏

A = 10ms，B= 0.5ms

| 优先级 | 执行顺序                                                     | 结论                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| A > B  | A(10ms)  ----->osdelay()----->B(0.5ms)------>osdelay()----->A(10ms)![image-20240702022858910.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20240702022858910.png) | AB都完整运行,B频率低                                         |
| A < B  | B(0.5ms)------>osdelay()----->A(0.5ms)被打断------->systick()---->B(0.5ms)![image-20240702022926610.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20240702022926610.png) | A会被B打断，A频率低                                          |
| A = B  | B(0.5ms)------>osdelay()----->A(1ms)时间片------>systick()----->B(0.5ms)![image-20240702022926610.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20240702022926610.png) | 时间片轮询，如果B没有调用挂起，则需要等待时间片耗尽。如果调用阻塞，则在阻塞后立刻切换到A |

### Freertos链表

**任务列表数组的每一个元素是一个链表，链表中的节点关联到TCB。**

**1.就绪链表（Ready List）**
就绪链表包含所有处于就绪状态的任务。就绪状态的任务是指已经准备好运行，但由于当前执行的任务正在占用 CPU 资源，它们暂时无法立即执行。这些任务按照优先级被组织在就绪链表中。当当前正在执行的任务释放 CPU（例如，由于时间片用完、任务阻塞或挂起等原因）时，调度器从就绪链表中选择优先级最高的任务来执行。

**2.阻塞链表（Blocked List）**
阻塞链表包含那些由于某种原因而无法立即执行的任务。这些原因可能包括等待某个事件、资源不可用、延时等情况。当任务处于阻塞状态时，它们不会被调度器所执行。这些任务会在特定条件满足之后重新放入就绪链表，等待调度器选择其执行。

**3.挂起链表（Suspended List）**
挂起链表包含已被显式挂起的任务。当任务被挂起时，它们暂时停止运行，不再参与调度。这些任务不会出现在就绪链表或阻塞链表中，因为它们被明确地挂起，不参与任务调度。![image-20240702181811152.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/image-20240702181811152.png)
[深入理解FreeRTOS_学习笔记(10.链表)_freertos链表-CSDN博客](https://blog.csdn.net/m0_65525149/article/details/130986152)

### 确定下一个运行的任务

- **位图**，表示哪些优先级有就绪任务。每个位对应一个优先级，如果某一位为1，表示该优先级有任务就绪。硬件加速，CLZ指令查找
  **前导0**（第一个1前0的个数），获取最高优先级列表。
- 任务列表数组，每个数组元素是一个链表，链表中的每个节点代表一个特定优先级的就绪任务。遍历查找



### 优先级翻转

使用信号量时。（互斥量、信号量、队列）

高优先级任务被低优先级任务阻塞，导致高优先级任务迟迟得不到调度。但其他中等优先级的任务却能抢到CPU资源。-- 从现象上来看，好像是中优先级的任务比高优先级任务具有更高的优先权。

![mutex002.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/mutex002.png)

- FreeRTOS 的**优先级继承机制**是一种用于解决优先级反转问题的手段。
- 低优先级任务占用资源的时候加锁，高优先级用的时候发现被锁了就把低优先级的优先级提高。

**优先级继承机制的工作原理**

1. **资源请求**：高优先级任务尝试获取一个被低优先级任务持有的互斥锁。
2. **优先级提升**：如果高优先级任务发现互斥锁被低优先级任务持有，FreeRTOS 会将低优先级任务的优先级提升到与高优先级任务相同的级别。这保证了低优先级任务能够尽快完成对资源的使用。
3. **资源释放**：当低优先级任务释放互斥锁时，它的优先级会恢复到原来的级别。
4. **调度**：高优先级任务可以获取互斥锁并继续执行。





## 2.每个任务有自己的东西

**每个任务的关键组成部分**

1. **任务控制块（TCB，Task Control Block）**：
   - 每个任务都有一个TCB，包含该任务的所有信息，如任务状态、优先级、任务堆栈的起始地址和当前堆栈指针等。
   - TCB在FreeRTOS中用于管理和调度任务。
2. **任务堆栈**：
   - 每个任务都有自己的堆栈空间，用于存储局部变量、函数调用返回地址和任务上下文（CPU寄存器的值）。
   - 堆栈空间是在创建任务时从共享内存（通常是SRAM）中分配的。
   - 采用heap4内存管理，分配的堆栈是连续的。

**共享内存和堆栈分配**

虽然STM32的内存是共享的，但任务堆栈的分配是通过分配内存区域来实现的，每个任务在创建时从共享内存中分配一块独立的堆栈空间。这种分配通常由FreeRTOS的内存管理函数（如`pvPortMalloc`）处理。

## 3.SVC中断和PendSV

- **SVC（Supervisor Call）**：
  - `SVC`中断就是软中断，给用户提供一个访问硬件的接口。
  - 主要用于启动第一个任务。
  - 通过 `svc` 指令触发并进入 SVC 异常处理程序。
- **PendSV（Pendable Service Call）**：
  - 专门用于任务上下文切换。
  - 被SysTick和taskyeild中断触发，优先级最低，在调度器需要切换任务时触发。
  - 通过设置 NVIC 的 PendSV 位触发，并在异常处理程序中保存和恢复任务上下文。

### SVC

SVC 用于产生系统函数的调用请求。
**当用户程序想要控制特定的硬件时，它就会产生一个 SVC 异常**，然后操作系统提供的 SVC 异常服务例程得到执行，它再调用相关的操作系统函数，后者完成用户程序请求的服务。

![20200807100320959.png](https://obsidian-1321127127.cos.ap-beijing.myqcloud.com/20200807100320959.png)

系统调用处理异常，用户与内核进行交互，用户想做一些内核相关功能的时候必须通过SVC异常，让内核处于异常模式，才能调用执行内核的源码。**触发SVC异常，会立即执行SVC异常代码**。

```c
void triggerSVC(void)
{
    __asm volatile ("svc 0");
}
```

**FreeRTOS中任务调度器触发了 `SVC` 中断来启动第一个任务，之后的工作都靠 `PendSV` 和 `SysTick` 中断触发来实现**

为什么要用SVC启动第一个任务？因为使用了OS，任务都交给内核。总不能像裸机调用普通函数一样启动一个任务。

### PendSV

`PendSV` 中断就是一个用来处理上下文切换的中断，可以由多种方式触发：

1. **`SysTick` 定时器中断**：这是最常见的触发方式，用于实现时间片轮转调度。
2. **其他中断**：其他中断处理程序也可以根据需要显式触发 `PendSV` 中断。
3. **任务调用**：任务本身也可以通过调用 `taskYIELD()` 或其他调度相关函数来触发 `PendSV` 中断。`osdelay`也可以触发，在阻塞任务的过程中，会将调度器先挂起，然后进行移动任务到阻塞链表的操作，再恢复调度器。恢复调度器后会自动检查是否需要进行任务切换，会触发`portYIELD_WITHIN_API`进行上下文切换。



## 4.上下文切换

当操作系统决定暂停当前正在执行的任务并开始执行另一个任务时，就会发生上下文切换。

**上下文切换的内容：**

1. **通用寄存器**：R0-R12
2. **堆栈指针**：PSP
3. **程序计数器**：PC
4. **链接寄存器**：LR
5. **程序状态寄存器**：xPSR
6. **浮点寄存器**

**切换步骤：**

1. 保存当前任务的上下文

2. 选择要运行的下一个任务

3. 加载新任务的上下文

4. 更新调度器状态

5. 执行新选定的任务

   

## 5.FreeRTOS中_FROM_ISR

作用：在中断中调用的API，其禁用了调度器，无延时等阻塞操作，保证临界区资源快进快出访问



## 6.中断和任务的关系

**中断和任务是操作系统处理并发性的两种基本机制。**

***\*中断：\****

- 中断通常由硬件设备（如定时器、外部设备）或软件请求（如系统调用）触发。

- 中断会暂停当前正在执行的程序，保存其上下文，并跳转到一个称为中断服务程序（ISR），完成后恢复程序继续执行。

- FreeRTOS 允许用户编写中断服务程序（ISR），用于响应硬件事件或外部触发的中断。
- 中断服务程序通常需要尽可能快速地完成执行，以便尽快恢复正常任务调度。

***\*任务：\****

- 任务是操作系统调度和管理的基本执行单元，通常指线程（Thread）或进程（Process）。

- FreeRTOS 通过调度器负责管理和调度多个任务，并确保它们按照优先级和就绪状态正确执行。
- 每个任务都有自己的堆栈空间、上下文信息等，由调度器进行管理。

***\*关系：\****

- 并发性：中断允许在某些事件发生时及时响应，而任务则允许多个代码块同时运行。

- 中断服务程序可能需要与任务进行通信或共享数据。这种情况下需要谨慎设计数据共享和同步机制。
- 中断可以唤醒阻塞状态下的任务，例如通过发送信号量或使用消息队列通知等机制。
- 任务可以在其执行过程中禁用某些中断（通过临界区保护）以确保关键代码段不被打断。

***\*FreeRTOS 中的应用：\****

- 中断通常用于处理硬件事件（如定时器、外设输入输出等），而任务用于实现更复杂的功能模块或业务逻辑。


***\*资源共享与同步：\****

- 在 FreeRTOS 中，需要注意在中断服务程序和任务之间共享资源时可能出现竞态条件问题。

- 可以使用信号量、消息队列等机制来实现资源共享和同步，在避免数据竞争方面起到重要作用。




## 7.高优先级打断低优先级中断

### NVIC

- NVIC（嵌套向量中断控制器）NVIC 是 ARM Cortex-M 系列处理器的一部分**是一种硬件结构**。
- NVIC 通过**中断向量表来管理中断**。
- 当中断发生时，处理器会根据**中断号从向量表中获取相应的中断服务程序地址**，然后开始执行相应的中断处理程序。
- NVIC 还负责中断优先级的管理，它可以根据**中断类型和配置的优先级来确定哪个中断应该被优先处理**。

### 中断抢占

当一个低优先级中断正在执行时，如果有一个高优先级的中断触发。通常会发生以下情况：

***\*1. \*\*中断抢占\*\*：\****当一个高优先级的中断触发时，如果其优先级高于当前正在执行的低优先级中断，处理器会立即中断当前正在执行的低优先级中断，并且开始执行高优先级中断的中断服务程序。这使得高优先级的中断能够迅速响应，保证了系统对重要事件的及时处理。

***\*2. \*\*中断嵌套\*\**\***：在一些处理器中，包括使用 NVIC 的 ARM Cortex-M 系列处理器，支持中断嵌套。这意味着当高优先级中断发生时，它可以抢占正在执行的低优先级中断，并执行其自己的中断服务程序。但是，一旦高优先级中断处理完毕，处理器会返回到被抢占的低优先级中断处继续执行。



## 8.任务调度通过SysTick进行

通过系统定时器中断触发。在ARM Cortex-M基础上的实现中，例如STM32微控制器，FreeRTOS通常使用**SysTick**定时器来生成操作系统节拍。SysTick是Cortex-M内核提供的一个系统定时器，专门设计用来支持操作系统。

 

## 9.消息队列

***\*### 消息队列的基本概念\****

消息队列允许一个或多个任务发送（写入）消息到队列中，而一个或多个任务可以从队列中接收（读取）消息。每个消息队列都有一个固定的长度，既可以存储固定数量的消息，也可以存储固定大小的数据项。

***\*### 如何创建消息队列\****

在FreeRTOS中，使用`xQueueCreate()`函数来创建一个新的消息队列。这个函数需要两个参数：队列可以容纳的最大消息数以及每个消息的大小（字节为单位）。

```c
QueueHandle_t xQueueCreate(UBaseType_t uxQueueLength, UBaseType_t uxItemSize);
```

\- `uxQueueLength` 是队列中可以保存的最大消息数。

\- `uxItemSize` 是队列中每个消息的大小（以字节为单位）。

***\*### 发送消息到队列\****

向队列发送消息可以使用`xQueueSend()`、`xQueueSendToFront()`、`xQueueSendToBack()`或`xQueueSendFromISR()`（从中断服务例程中发送）等函数。这些函数允许将消息放入队列的尾部或头部。

```c
BaseType_t xQueueSend(QueueHandle_t xQueue, const void * pvItemToQueue, TickType_t xTicksToWait);
```

\- `xQueue` 是消息队列的句柄。

\- `pvItemToQueue` 是指向要发送的消息的指针。

\- `xTicksToWait` 是任务在消息可以发送到队列之前愿意等待的时间（以节拍为单位）。

***\*### 从队列接收消息\****

从队列接收消息可以使用`xQueueReceive()`函数，它从队列中取出最早的消息。

```c
BaseType_t xQueueReceive(QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait);
```

\- `xQueue` 是消息队列的句柄。

\- `pvBuffer` 是指向接收消息的缓冲区的指针。

\- `xTicksToWait` 是任务在接收到消息之前愿意等待的时间（以节拍为单位）。

**\#示例**

假设有一个任务负责读取传感器数据，另一个任务负责处理这些数据。可以创建一个消息队列，传感器读取任务将数据发送到队列，而数据处理任务从队列接收数据。

```c
// 创建消息队列
QueueHandle_t xQueue = xQueueCreate(10, sizeof(int));
// 发送数据到队列
int sensorData = 123;
if(xQueueSend(xQueue, &sensorData, (TickType_t)10) != pdPASS) {
  // 处理发送失败的情况
}

// 从队列接收数据
int receivedData;
if(xQueueReceive(xQueue, &receivedData, (TickType_t)10) == pdPASS) {
  // 使用接收到的数据
}
```

***\*使用消息队列的中断安全函数\****

由于在中断上下文中不能使用标准的队列操作函数（如xQueueSend或xQueueReceive），FreeRTOS 提供了特别设计用于从ISR中调用的函数。这些函数的名字通常以FromISR后缀结尾，例如：

```c
xQueueSendFromISR()

xQueueSendToFrontFromISR()

xQueueSendToBackFromISR()

xQueueReceiveFromISR()
```





## 10.消息队列和共享内存的区别是什么，消息队列是如何做防止两个任务同时使用的

***\*消息队列和共享内存是两种常见的进程或任务间通信（IPC）机制\****，它们在用途、实现和适用场景上有显著的区别。选择哪种机制取决于应用的具体需求，包括数据传输的复杂性、同步需求、性能考虑等因素。

***\*### 消息队列\****

消息队列是一个先入先出（FIFO）的数据结构，用于存储待处理的消息。进程或任务可以将消息发送到队列，其他进程或任务可以从队列接收消息。消息队列提供了一种松耦合的通信方式，发送者和接收者不需要同时在线，也不需要直接知道对方的存在。

***\**\*优点\*\*：\****

\- **同步与异步通信**：支持同步和异步消息传递。

\- **松耦合**：发送者和接收者之间的松耦合使得系统组件更容易管理和维护。

\- **消息传递**：可以跨不同进程安全地传递复杂的数据结构。

***\**\*缺点\*\*：\****

\- **性能开销**：每条消息的发送和接收都涉及到系统调用，可能比共享内存方式更慢。

\- **资源限制**：系统对可用消息队列的数量和大小可能有限制。

***\*### 共享内存\****

共享内存允许两个或多个进程共享一个给定的存储区，是最快的IPC方法之一。所有共享内存的进程都可以直接读写这块内存。

***\**\*优点\*\*：\****

\- **性能**：因为数据不需要在进程间复制，所以共享内存通常提供了最高的数据传输速率。

\- **直接访问**：进程可以直接对内存进行读写操作，减少了中间层的开销。

***\**\*缺点\*\*：\****

\- **同步复杂性**：当多个进程需要访问共享内存时，需要额外的同步机制（如互斥锁、信号量等）来防止数据竞态和一致性问题。

\- **安全性和健壮性**：不当的内存访问可能导致数据损坏或程序崩溃。

***\*### 防止同时使用\****

消息队列自身通过内部的锁（如互斥锁）和同步机制来保证在任一时刻只有一个任务能够对其进行操作，从而避免了并发访问的问题。发送和接收消息的操作通常是原子的，操作系统确保了消息的完整性和队列的状态一致性。

共享内存区别于消息队列，在于它不提供内建的同步机制。使用共享内存时，开发者需要使用其他同步工具，如信号量或互斥锁，来防止多个进程同时访问内存区域，确保数据一致性和防止竞态条件。

***\*### 总结\****

选择消息队列还是共享内存取决于具体的应用场景。如果IPC涉及复杂的数据结构或者需要保证通信双方的解耦，消息队列可能是更好的选择。如果性能是首要考虑因素，并且开发者可以妥善管理同步问题，共享内存可能是更合适的选择。在实际应用中，这两种机制有时会结合使用，以达到既快速又可靠的通信。

 

## 11.消息队列，传入和传出时发生了什么

***\*消息队列\****是一种重要的进程间通信（IPC）机制，允许进程或线程安全地交换信息。这种机制通过在内存中创建一个队列来实现，进程可以向队列中添加消息，并从中读取消息。

***\*传入（发送）消息时发生了什么\****

1. **消息序列化**：如果消息不是原始二进制形式，它首先被序列化或打包成一种标准格式，以便安全地通过队列传输。这对于复杂的数据结构或跨语言通信尤其重要。
2. **队列访问**：发送进程通过操作系统API请求向指定的消息队列发送消息。如果队列实现了访问控制，操作系统将验证进程是否有权写入队列。
3. **消息排队**：操作系统将消息放入队列的尾部。如果队列设置了消息优先级，系统会根据优先级将消息插入到适当的位置。
4. **阻塞和超时**：如果队列已满，发送进程可能会根据API调用的具体参数被阻塞，直到队列中有足够的空间为止，或者操作超时。
5. **通知接收者**：一旦消息被成功排队，操作系统可能会通知一个或多个等待接收消息的进程，告知它们现在队列中有消息可用。

***\*### 传出（接收）消息时发生了什么\****

1. **队列访问**：接收进程通过操作系统API请求从消息队列中读取消息。和发送过程一样，如果实现了访问控制，将进行权限检查。

2. **消息检索**：操作系统从队列的头部检索消息，如果队列是空的，接收进程根据API调用的参数可能会阻塞，直到有消息到达，或者操作超时。

3. **消息反序列化**：接收到的消息如果需要，将被反序列化或解包，转换回适用于接收进程的数据结构。

4. **确认处理**：在某些系统中，接收进程可能需要显式确认它已成功处理消息，特别是在需要消息可靠性的场景中。这样可以允许系统在消息未成功处理时重试传递。

5. **资源管理**：消息被成功接收并处理后，相关的系统资源（如内存）将被回收，以便再次使用。

   

## 12.临界区

在 FreeRTOS 中，临界区的作用是确保某段代码在执行过程中不会被中断或调度器切换到其他任务，从而保护共享资源免受并发访问的影响。不是一种通信。

进入临界区的两种方式

```c
taskENTER_CRITICAL();
// 代码
taskEXIT_CRITICAL();

vTaskSuspendAll();
//代码
xTaskResumeAll();
```

**临界区应尽可能小**：进入临界区会禁止中断或暂停调度，这可能会影响系统的实时性和响应性。因此，临界区应尽可能小，只保护必要的代码段。

**避免在临界区中调用可能阻塞的函数**：在临界区中调用可能阻塞的函数（如等待信号量、消息队列等）会导致系统死锁或任务调度问题。

**选择合适的方法**：全局中断禁止的临界区适用于需要保证极高安全性的场合，但会影响所有中断；调度器暂停的方法更温和，只会影响任务调度，不会影响中断处理。

### 什么时候使用临界区

1. **访问共享硬件资源**：多个任务需要访问同一个硬件外设（例如 UART、I2C、SPI 等）。
2. **操作共享数据结构**：多个任务需要操作同一个链表、队列或其他复杂数据结构。
3. **更新全局配置**：多个任务可能需要读取和更新全局配置参数。

**示例：任务间共享一个全局变量**

假设有两个任务 `Task1` 和 `Task2`，它们共享一个全局变量 `counter`。如果不使用临界区，在某些情况下可能会导致数据竞争，导致 `counter` 的值不正确。

**不使用临界区的情况**

```c
int counter = 0;

void Task1(void *pvParameters) {
    while (1) {
        counter++;
        vTaskDelay(pdMS_TO_TICKS(100));
    }
}

void Task2(void *pvParameters) {
    while (1) {
        counter--;
        vTaskDelay(pdMS_TO_TICKS(100));
    }
}
```

在这个例子中，`Task1` 和 `Task2` 都在对 `counter` 进行操作。由于 `counter++` 和 `counter--` 不是原子操作，可能会发生以下情况：

- `Task1` 读取 `counter` 的值。
- 任务切换到 `Task2`，`Task2` 修改 `counter` 的值。
- 再次切换回 `Task1`，`Task1` 使用过时的 `counter` 值进行加操作。

这种情况会导致 `counter` 的值不正确。

**使用临界区的情况**

为了避免上述问题，我们可以在访问 `counter` 时使用临界区：

```c
int counter = 0;

void Task1(void *pvParameters) {
    while (1) {
        taskENTER_CRITICAL();
        counter++;
        taskEXIT_CRITICAL();
        vTaskDelay(pdMS_TO_TICKS(100));
    }
}

void Task2(void *pvParameters) {
    while (1) {
        taskENTER_CRITICAL();
        counter--;
        taskEXIT_CRITICAL();
        vTaskDelay(pdMS_TO_TICKS(100));
    }
}
```

在这个修改后的例子中，每个任务在访问 `counter` 时都使用了 `taskENTER_CRITICAL()` 和 `taskEXIT_CRITICAL()` 来保护临界区。这样可以确保在 `counter` 进行加或减操作时不会被其他任务打断，从而避免数据竞争。



## 13.互斥锁Mutex、自旋锁Spin

当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对

互斥锁：Mutex，独占锁，谁上锁谁有权释放，申请上锁失败后阻塞，不能在中断中调用

自旋锁：Spinlock：申请上锁失败后，一直判断是否上锁成功，消耗CPU资源，可在中断中调用

**注：互斥锁有优先级继承，信号量没有。**

## 14.死锁和递归

死锁会发生在以下情况下：
1. **非递归锁**：如果任务已经持有某个锁，递归调用函数时再次获取同一个锁，则会导致死锁，因为该任务会无限期等待自己释放该锁，而自己已经被阻塞在等待锁释放的状态。
   
2. **锁的顺序不当**：如果在递归调用过程中，不同的锁按照不同的顺序被获取，可能导致死锁。

**递归锁的解决方案**

1. **递归锁（可重入锁）**：使用递归锁，它允许同一个任务多次获取同一个锁，而不会被阻塞。每次锁被获取，内部计数器增加；每次锁被释放，计数器减少，只有计数器为零时，锁才会真正被释放。
   
2. **避免在递归中使用锁**

**示例代码**

下面是一个示例，展示如何在递归函数中使用递归锁（可重入锁）来避免死锁：

```c
typedef struct {
    SemaphoreHandle_t mutex;  // 用于实际锁操作的FreeRTOS互斥信号量
    TaskHandle_t owner;       // 当前持有锁的任务的句柄
    UBaseType_t count;        // 当前任务持有锁的次数（递归锁的计数器）
} RecursiveLock_t;

void RecursiveLock_Init(RecursiveLock_t *lock) {
    lock->mutex = xSemaphoreCreateMutex();  // 创建一个互斥信号量
    lock->owner = NULL;                     // 初始化锁的拥有者为空
    lock->count = 0;                        // 初始化计数器为0
}

void RecursiveLock_Lock(RecursiveLock_t *lock) {
    TaskHandle_t currentTask = xTaskGetCurrentTaskHandle();  // 获取当前任务的句柄
    if (lock->owner == currentTask) {
        // 如果当前任务已经拥有该锁，则增加计数器
        lock->count++;
    } else {
        // 如果当前任务没有该锁，则尝试获取锁
        xSemaphoreTake(lock->mutex, portMAX_DELAY);  // 等待获取互斥信号量
        lock->owner = currentTask;                   // 设置当前任务为锁的拥有者
        lock->count = 1;                             // 初始化计数器为1
    }
}

void RecursiveLock_Unlock(RecursiveLock_t *lock) {
    TaskHandle_t currentTask = xTaskGetCurrentTaskHandle();  // 获取当前任务的句柄

    if (lock->owner == currentTask) {
        // 如果当前任务是锁的拥有者，则减少计数器
        if (--lock->count == 0) {
            // 如果计数器减为0，则释放锁
            lock->owner = NULL;                    // 重置锁的拥有者
            xSemaphoreGive(lock->mutex);           // 释放互斥信号量
        }
    }
}

RecursiveLock_t lock;  // 定义一个全局递归锁

void RecursiveFunction(int n) {
    RecursiveLock_Lock(&lock);  // 锁定资源
    // 递归结束条件
    if (n <= 0) {
        RecursiveLock_Unlock(&lock);  // 释放资源
        return;
    }
    // 递归调用
    RecursiveFunction(n - 1);
    RecursiveLock_Unlock(&lock);  // 释放资源
}
```



## 15.临界区与锁的对比

互斥锁与临界区的作用非常相似，但互斥锁（mutex）是可以命名的，也就是说它可以跨越进程使用。所以创建互斥锁需要的资源更多，所以如果只为了在进程内部使用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥锁是跨进程的互斥锁一旦被创建，就可以通过名字打开它。

临界区是一种轻量级的同步机制，与互斥和事件这些内核同步对象相比，临界区是用户态下的对象，即只能在同一进程中实现线程互斥。因无需在用户态和核心态之间切换，所以工作效率比较互斥来说要高很多。

|        | 使用场景             | 操作权限           |
| ------ | -------------------- | ------------------ |
| 临界区 | 一个进程下不同线程间 | 用户态，轻量级，快 |
| 互斥锁 | 进程间或线程间       | 内核态，切换，慢   |



## 16.同步互斥锁在消息队列如何应用

**互斥**：

互斥是通过某种锁机制（如互斥锁、信号量等）实现的，它确保在任何给定时刻，只有一个线程或进程可以操作消息队列。

1. **加锁**：任务操作消息队列时，首先尝试获得与队列关联的锁。如果锁已被其他线程占用，该线程将等待直到锁变为可用状态。
2. **执行操作**：一旦获得锁，线程就可以安全地执行其操作。
3. **释放锁**：操作完成后，线程释放锁。

**同步**：

确保生产者不会在队列满时尝试添加消息，消费者不会在队列空时尝试读取消息。

- **实际操作：**读取函数会有返回值，等于ture的时候才允许操作，否则挂起。

### **实际应用**

- FreeRTOS内部已经实现了线程安全机制，因此不需要额外的锁来保护对队列的访问。
- 具体来说，FreeRTOS的队列在内部使用了信号量（Semaphore）来保证多个任务（Task）对队列的并发访问是安全的。
- 在任务或者中断中调用消息队列传输的时候会进入临界区。
- 中断函数中有专门的ISR函数，不会执行阻塞操作，而且尝试直接写入，如果写入失败会返回false。



## 17.如何使消息队列性能更优（索引方式）

**使用索引来优化消息队列的传输效率，而不是直接传输大量数据。通过这种方式，减少了在消息队列中的数据传输量，同时提高了系统的整体性能。**

**传统方法：**

```
css复制代码消息队列
[ 数据块1 ][ 数据块2 ][ 数据块3 ] ...
```

- 每次传输大量数据，内存占用和传输时间较长。

**使用索引的方法：**

```
css复制代码消息队列
[ 索引1 ][ 索引2 ][ 索引3 ] ...

内存池
[ 数据块1 ][ 数据块2 ][ 数据块3 ] ...
```

- 消息队列中仅传输索引，内存池中存储实际数据。

**实现步骤**

1. **预分配内存块**：在系统初始化时，分配一定数量的固定大小的内存块。这些内存块用于存储实际的数据。

2. **空闲队列**：维护一个空闲内存块的队列。当需要发送数据时，从空闲队列中取出一个内存块。

3. **填充数据**：将数据填充到取出的内存块中。

4. **索引入队**：将内存块的索引（或指针）放入消息队列中。

5. **消费数据**：接收任务从消息队列中取出索引，通过索引找到对应的内存块，处理其中的数据。

6. **释放内存块**：处理完数据后，将内存块归还到空闲队列中。

### 示例代码

下面是一个使用 FreeRTOS 的示例代码，演示如何通过索引来优化消息队列的数据传输：

```c
#include "FreeRTOS.h"
#include "task.h"
#include "queue.h"
#include <stdio.h>

#define NUM_BLOCKS 10  // 内存块数量
#define BLOCK_SIZE sizeof(SensorData)  // 每个内存块的大小

// 传感器数据结构
typedef struct {
    float temperature;  // 温度
    float humidity;     // 湿度
    uint32_t timestamp; // 时间戳
} SensorData;

// 内存块结构
typedef struct {
    SensorData data;  // 传感器数据
} MemoryBlock;

MemoryBlock memoryPool[NUM_BLOCKS];  // 内存池数组
QueueHandle_t freeQueue;  // 空闲内存块队列
QueueHandle_t readyQueue; // 准备就绪内存块队列

// 初始化内存池
void initMemoryPool() {
    freeQueue = xQueueCreate(NUM_BLOCKS, sizeof(int));  // 创建空闲队列
    readyQueue = xQueueCreate(NUM_BLOCKS, sizeof(int)); // 创建就绪队列

    // 将所有内存块索引添加到空闲队列中
    for (int i = 0; i < NUM_BLOCKS; i++) {
        xQueueSend(freeQueue, &i, 0);
    }
}

// 传感器任务
void sensorTask(void *pvParameters) {
    int blockIndex;
    while (1) {
        // 从空闲队列中获取一个内存块索引
        if (xQueueReceive(freeQueue, &blockIndex, portMAX_DELAY) == pdPASS) {
            // 填充内存块中的传感器数据
            memoryPool[blockIndex].data.temperature = 25.0;  // 示例温度数据
            memoryPool[blockIndex].data.humidity = 60.0;     // 示例湿度数据
            memoryPool[blockIndex].data.timestamp = xTaskGetTickCount();  // 当前时间戳

            // 将内存块索引放入准备就绪队列
            xQueueSend(readyQueue, &blockIndex, portMAX_DELAY);
        }
        vTaskDelay(pdMS_TO_TICKS(1000));  // 模拟传感器读取间隔
    }
}

// 数据处理任务
void processingTask(void *pvParameters) {
    int blockIndex;
    while (1) {
        // 从准备就绪队列中获取一个内存块索引
        if (xQueueReceive(readyQueue, &blockIndex, portMAX_DELAY) == pdPASS) {
            // 处理内存块中的传感器数据
            SensorData *data = &memoryPool[blockIndex].data;
            printf("Temperature: %.2f, Humidity: %.2f, Timestamp: %lu\n",
                   data->temperature, data->humidity, data->timestamp);

            // 将内存块索引归还到空闲队列
            xQueueSend(freeQueue, &blockIndex, portMAX_DELAY);
        }
    }
}

int main(void) {
    // 初始化内存池
    initMemoryPool();

    // 创建传感器任务
    xTaskCreate(sensorTask, "SensorTask", configMINIMAL_STACK_SIZE, NULL, 1, NULL);
    // 创建数据处理任务
    xTaskCreate(processingTask, "ProcessingTask", configMINIMAL_STACK_SIZE, NULL, 1, NULL);

    // 启动调度器
    vTaskStartScheduler();
    for (;;);
}

```

### 消息队列如何变化

**初始状态**

- `freeQueue`：`[0, 1, 2]`
- `readyQueue`：`[]`

**第一次传感器任务执行**

- `freeQueue`：`[1, 2]`
- `readyQueue`：`[0]`

**第一次数据处理任务执行**

- `freeQueue`：`[1, 2, 0]`
- `readyQueue`：`[]`

**第二次传感器任务执行**

- `freeQueue`：`[2, 0]`
- `readyQueue`：`[1]`

**第二次数据处理任务执行**

- `freeQueue`：`[2, 0, 1]`

- `readyQueue`：`[]`

  

## 18.STM32如果跑飞在异常中，怎么处理和定位问题？

https://www.cnblogs.com/yanxiaodong/p/13793274.html



## 19.如果一个系统内有一个高频的（20KHz）任务需要进行调度，应该怎么去设计实现？

***1.\**** ***\*确定任务优先级\****

\- **高频任务优先级**：高频任务通常应该有较高的优先级，以确保它能够按时调度执行。然而，优先级过高可能会导致低优先级任务饿死，特别是如果高频任务执行时间较长。

\- **优先级分配**：为系统中的所有任务分配合理的优先级，确保重要的任务（如紧急的错误处理）仍然能够及时执行。

***2.\**** ***\*设计任务执行时间\****

\- **执行时间短**：确保高频任务执行时间尽可能短，这样它才不会占用太多CPU时间，影响到其他任务。

\- **时间确定性**：任务的执行时间应该是确定的，避免在任务中调用可能导致不确定延迟的函数，如那些依赖外部资源的函数。

***3.\**** ***\*使用定时器或中断\****

\- **硬件定时器**：考虑使用硬件定时器来触发高频任务的执行。这样可以减少操作系统的负担，特别是在非常高的频率下。

\- **中断服务例程（ISR）**：如果任务对时间的要求非常严格，可以考虑将其实现为中断服务例程。但请注意，ISR中应避免执行长时间操作，并且只做最必要的处理。

***4.\**** ***\*使用信号量或事件组同步\****

\- 如果高频任务需要与其他任务交互，考虑使用信号量或事件组来进行同步。确保同步机制的使用不会导致任务被不必要地阻塞。

***5.\**** ***\*测试和验证\****

\- **性能测试**：使用FreeRTOS提供的工具和方法（如运行时间统计）来测试系统的实时性能，确保高频任务不会导致资源竞争或任务饥饿。

\- **优化**：根据测试结果进行必要的优化，可能包括调整任务优先级、优化任务代码，或改变任务调度策略。

***6.\**** ***\*实现示例\****

在FreeRTOS中，你可以使用`xTimerCreate`和`xTimerStart`创建和启动一个硬件定时器，或者使用`vTaskDelayUntil()`函数来创建一个周期性执行的任务。





## 20.FreeRTOS和Linux区别

最大的区别在于实时性，RTOS实时性好

| **特性**                 | **FreeRTOS**                                                 | **Linux**                                                    |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **设计目标和应用场景**   | 开源的实时操作系统（RTOS），适用于资源受限的嵌入式系统，如工业控制、物联网设备、汽车电子等。 | 通用开源操作系统，适用于个人电脑、服务器、移动设备和嵌入式系统等多种计算环境，功能全面，支持广泛的硬件设备。 |
| **实时性**               | 提供确定性的任务调度，保证任务在严格定义的时间内完成，适合需要快速响应外部事件的应用。 | 标准Linux内核不是实时操作系统，提供良好的平均性能，但不保证确定性的响应时间。实时Linux变种（如PREEMPT_RT）可以提供更好的实时性能，但仍不及FreeRTOS。 |
| **资源需求**             | 内核小巧，几千字节内存即可运行，非常适合资源受限的环境。     | 资源需求较高，优化后的嵌入式Linux版本也需要至少数十兆字节的内存和更多的存储空间。 |
| **用户接口和开发复杂度** | 提供简洁的API管理任务、中断、同步机制等，适合直接在硬件上运行的应用程序开发。 | 提供丰富的用户界面和应用程序接口，支持图形界面、网络通信、文件系统等复杂功能。开发人员可使用多种编程语言和工具进行开发。 |
| **社区和生态系统**       | 具有活跃的社区和一些第三方库，但生态系统相对较小。           | 拥有庞大的开发者社区和丰富的软件生态系统，包括数以万计的应用程序和库，以及广泛的硬件支持。 |



### 最大的区别的实时性

***\*在实时性、中断处理和应用场景这三个方面，FreeRTOS和Linux表现出了显著的差异\****，这些差异直接影响了它们各自最适合的应用类型。

| **特性**     | **FreeRTOS**                                                 | **Linux**                                                    |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **实时性**   | 作为一个实时操作系统（RTOS），提供确定性的响应时间，保证系统在指定时间内响应外部事件。适用于需要快速和可预测响应的应用，如工业自动化和汽车电子系统。 | 标准Linux内核不是实时操作系统，调度器注重吞吐量和平均响应时间，不保证任务的最大延迟。实时Linux（如PREEMPT_RT）提高了实时性能，但仍不及专门设计的RTOS（如FreeRTOS）。 |
| **中断处理** | 中断处理设计为尽可能简短和快速。提供机制最小化中断服务例程（ISR）的执行时间，如允许从ISR中直接发送信号到任务或使用半任务（Half Task）处理。这保证了系统的实时性能。 | 中断处理相对较重，需处理更多上下文和系统状态。尽管进行了优化以快速处理中断，但在高负载或复杂系统中，中断响应时间可能不如RTOS。对于需要高优先级实时任务的系统，这可能成为问题。 |



### 中断造成的实时性差异

***\*Linux是软中断，rtos的中断是由nvic模块实现，中断是实时的，会立即响应或者不响应。Linux响应有延时\****

**RTOS中的中断**：

- 在RTOS中，中断通常由硬件直接管理，由嵌套向量中断控制器**（NVIC）**模块实现。NVIC负责管理和优先排序硬件中断，确保对**高优先级中断的快速响应**。

- RTOS设计以实时性为核心，这意味着系统能够保证在指定的、严格的时间限制内响应外部事件。因此，当中断发生时，RTOS能够确保几乎立即响应，或者基于预定义的优先级规则不响应。这种行为对于需要快速且一致响应外部事件的应用至关重要。


**Linux中的中断和软中断**：

- Linux操作系统区分硬中断（Hardware Interrupts）和软中断（Softirqs）/任务延迟（Tasklets）等机制。硬中断由硬件直接触发，而软中断是一种机制，用于在中断上下文之外处理中断相关的工作，这可以提高系统的整体性能和可扩展性。

- 软中断在Linux中用于分担一些不能在硬中断处理程序中执行的处理工作，比如说数据包处理等。这是因为硬中断处理程序需要尽可能快地执行并返回，以避免阻塞其他中断。**软中断可以被延迟执行**，这意味着它们的响应时间可能比直接的硬中断处理稍有延迟。


**响应延时的理解：**

- 当提到“Linux响应有延时”，主要是相对于RTOS直接和几乎立即处理硬中断的能力而言。Linux的软中断机制虽然提高了系统的灵活性和处理能力，但在面对需要极快响应的实时任务时，可能无法像RTOS那样提供最低延迟的保证。

- 这并不意味着Linux无法处理高速的或者实时的任务，但它的设计优先考虑的是灵活性和通用性，而非最严格意义上的实时响应。实时Linux变种（如使用PREEMPT_RT补丁的Linux）通过修改内核调度器和锁机制等方式，努力缩短响应时间，提高实时性。






## 21.Freertos内核中的驱动隔离

实现驱动隔离的主要目的是为了提高代码的模块性和可维护性，同时减少上层应用与硬件之间的直接依赖。

驱动隔离通常意味着创建一个抽象层，使应用代码与硬件操作解耦。

### 如何在STM32使用FreeRTOS实现驱动隔离

1. **驱动抽象层（HAL）**：
   - STM32通过其硬件抽象层（HAL）库提供了一个很好的起点，这些库封装了对硬件的直接访问，如GPIO, ADC, UART等。
   - 创建自定义的驱动抽象函数或接口，这些接口函数封装HAL函数，为应用层提供统一的调用接口。

2. **设备驱动接口**：
   - 定义设备驱动结构体，包含指向功能函数的指针（如初始化、读、写、关闭等）。
   - 应用层通过调用这些结构体中的函数指针来操作硬件，而无需关心具体的硬件细节。

3. **中间件层**：
   - 可以在HAL和应用层之间实现一个中间件层，这层处理更复杂的逻辑，如设备的状态管理、错误处理等。
   - 中间件层同样提供API，这些API基于设备驱动层的功能，向上提供更高层的服务。

4. **任务和信号量**：
   - 在FreeRTOS中，利用任务（Tasks）来隔离不同功能模块，每个任务处理特定的逻辑。
   - 使用信号量（Semaphores）或互斥锁（Mutexes）来管理对共享资源的访问，确保数据访问的线程安全。

5. **消息队列**：
   - 使用消息队列（Queues）来在任务之间传递数据，减少直接的任务间交互，可以通过队列发送消息或命令，从而驱动硬件操作。

6. **事件组和中断**：
   - 利用事件组来处理多个任务或中断之间的事件同步。
   - 在中断服务例程（ISR）中，尽量减少执行时间和复杂操作，使用中断来通知任务处理具体事件。

**示例代码概念**

假设我们需要为STM32中的一个UART接口写一个驱动，我们可以按照下面的步骤进行：

```c
// UART驱动接口
typedef struct {
    void (*init)(uint32_t baud_rate);
    void (*transmit)(const uint8_t* buffer, size_t size);
    void (*receive)(uint8_t* buffer, size_t size);
} UART_DriverInterface;

// 实现该接口
void UART_Init(uint32_t baud_rate) {}
void UART_Transmit(const uint8_t* buffer, size_t size)}
void UART_Receive(uint8_t* buffer, size_t size) {}

// 创建一个驱动结构体实例
UART_DriverInterface uart_driver = {
    .init = UART_Init,
    .transmit = UART_Transmit,
    .receive = UART_Receive
};

// 应用层调用
void app_function() {
    uart_driver.init(9600);
    uart_driver.transmit("Hello", 5);
}
```

通过这样的结构，应用代码与底层硬件操作解耦，便于维护和可扩展性。



### 在FreeRTOS上设计一个驱动框架

在FreeRTOS上设计一个驱动框架，以便更好地解耦上层应用和底层硬件驱动，可以借鉴Linux和RT-Thread中的驱动设计思路。以下是详细的设计步骤和思路：

**1. 驱动框架设计原则**

- **抽象硬件层（HAL）**：利用STM32 HAL库提供的硬件抽象层，使驱动程序可以直接调用HAL库来与硬件进行交互。
- **标准化接口**：定义统一的接口（如open、read、write、ioctl），使得上层应用可以通过这些接口来操作驱动，而不需要关心底层硬件的具体实现。
- **模块化设计**：每个驱动模块独立，实现特定硬件的操作，以便于维护和扩展。
- **线程安全**：确保驱动在多任务环境中是线程安全的，可以通过信号量、互斥锁等机制来实现。

**2. 驱动框架结构**

- **驱动管理层**：负责驱动的注册、注销和查找。
- **驱动接口层**：定义统一的驱动操作接口，如open、read、write、ioctl等。
- **驱动实现层**：每个具体的驱动实现，如UART驱动、I2C驱动等。

**3. 具体实现步骤**

**3.1 驱动接口定义**

首先定义驱动的通用接口，这些接口包括初始化、打开、读取、写入和控制等操作。

```c
typedef struct {
    int (*init)(void);
    int (*open)(void);
    int (*read)(char *buffer, int size);
    int (*write)(const char *buffer, int size);
    int (*ioctl)(int cmd, void *arg);
} driver_ops_t;

typedef struct {
    const char *name;
    driver_ops_t *ops;
} driver_t;
```

**3.2 驱动管理层**

实现一个驱动管理器，用于注册和查找驱动。

```c
#define MAX_DRIVERS 10

static driver_t *drivers[MAX_DRIVERS];
static int driver_count = 0;

int register_driver(driver_t *drv) {
    if (driver_count < MAX_DRIVERS) {
        drivers[driver_count++] = drv;
        return 0;
    }
    return -1;
}

driver_t* get_driver(const char *name) {
    for (int i = 0; i < driver_count; i++) {
        if (strcmp(drivers[i]->name, name) == 0) {
            return drivers[i];
        }
    }
    return NULL;
}
```

**3.3 驱动实现层**

每个具体的驱动实现，比如UART驱动，可以这样实现：

```c
#include "stm32f4xx_hal.h"

static int uart_init(void) {
    // UART初始化代码
    return 0;
}

static int uart_open(void) {
    // 打开UART
    return 0;
}

static int uart_read(char *buffer, int size) {
    // 从UART读取数据
    return HAL_UART_Receive(&huart1, (uint8_t *)buffer, size, HAL_MAX_DELAY);
}

static int uart_write(const char *buffer, int size) {
    // 向UART写入数据
    return HAL_UART_Transmit(&huart1, (uint8_t *)buffer, size, HAL_MAX_DELAY);
}

static int uart_ioctl(int cmd, void *arg) {
    // UART控制操作
    return 0;
}

driver_ops_t uart_ops = {
    .init = uart_init,
    .open = uart_open,
    .read = uart_read,
    .write = uart_write,
    .ioctl = uart_ioctl,
};

driver_t uart_driver = {
    .name = "uart1",
    .ops = &uart_ops,
};
```

在系统初始化时注册驱动：

```c
void system_init(void) {
    register_driver(&uart_driver);
}
```

**3.4 上层应用使用驱动**

上层应用通过统一接口使用驱动，而不需要关心具体实现。

```c
void app_main(void) {
    driver_t *uart = get_driver("uart1");
    if (uart && uart->ops->open()) {
        char buffer[100];
        uart->ops->read(buffer, sizeof(buffer));
        // 处理读取的数据
    }
}
```



## 22.如何设计任务

依据任务对响应的敏感性、执行时长（RTOS抢占式，会导致饥饿）

串口接收中断等任务优先级最高

电机PID计算以及控制需要固定控制周期，优先级较高

看门狗，按键处理中等、

最低的APP层的心跳和信息显示任务

**根据任务的控制频率和运行时间**（举例：视觉任务，算三角函数超时，一个三角函数6us 一个exp函数15us左右）



## 23.FreeRTOS的核心机制

实时操作系统（RTOS）的核心是其调度机制和任务管理。以下是RTOS最重要的几个核心概念和机制：

**1. 任务调度**

- **优先级调度**：高优先级任务优先运行。
- **时间片轮转**：为每个任务分配一个固定的时间片，轮流执行。
- **抢占式调度**：高优先级任务可以抢占低优先级任务的CPU时间。

**2. 任务管理**

RTOS提供了任务**创建、删除、挂起、恢复**等管理功能。

**3. 中断管理**

RTOS需要高效地处理中断。**FROM_ISR**

**4. 同步和通信机制**

- **信号量**（Semaphore）：用于任务间的同步和互斥。
- **互斥锁**（Mutex）：防止多个任务同时访问共享资源。
- **消息队列**（Message Queue）：用于任务间传递数据。
- **事件标志组**（Event Flags）：用于任务间的事件通知。
- **邮件箱**（Mailbox）：用于发送和接收消息。

**5. 内存管理**

RTOS提供动态内存管理机制，包括内存分配和释放，确保系统能够高效地利用内存资源。

**6. 上下文切换**

上下文切换是RTOS切换任务时保存和恢复任务状态的机制。它包括保存当前任务的CPU寄存器、堆栈指针和其他状态，并恢复新任务的这些状态。



## 24.RTOS如何任务调度

1. FreeRTOS在任务调度中有两种策略：优先级抢占和时间片轮询。
2. 创建任务的时候会给不同的任务分配不同的优先级，优先级是存储在对应任务的TCB中。
3. RTOS任务调度的底层是依赖就绪列表和阻塞列表进行的。
4. 列表的每个元素对应不同优先级的链表，链表中的每个节点关联到了不同任务的TCB。
5. 当系统触发了任务调度的时候，一般是当前任务主动阻塞（`vtaskyeild`）或者`systick`触发`pendsv`中断。
6. 会先执行保存上下文的操作，PC、通用寄存器、堆栈指针PSP、链接寄存器LR、程序状态寄存器xPSR、浮点寄存器。
7. 把当前任务移到阻塞列表中。
8. 执行`vTaskSwitchContext`函数，一般会先检查一个任务优先级的位图，通过硬件加速，CLZ指令查找**前导0**（第一个1前0的个数），获取最高优先级链表。
9. 在当前链表中选取任务，关联到新任务的TCB，然后恢复新任务的上下文，最后执行新任务。

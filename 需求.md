# 要求
- 编程一个solution.py python程序，将一个markdown格式的笔记中的内容，生成一个csv格式文件
- 保存大模型api调用的问答log
- 答案的输出使用markdown格式，并且需要正确换行
- 添加一些打印log信息，帮助用户了解当前运行情况
# 细节
## markdown格式
目标文件是：`嵌入式笔记.md`
markdown文件是一个知识点笔记
格式如下：
```txt
# 一级标题
## 二级标题
内容
# 一级标题
...
```
## csv格式
csv文件是一个知识点表格
格式如下：
```txt
问题 答案 
...
```

## 大模型api
### 需求和prompt设计
对于每一个二级标题的标题和内容，需要调用 大模型api 把对应的标题和内容，生成一个问题和答案。
示例prompt
```txt
请将以下Markdown格式的笔记转换为“问题+答案”的形式，具体要求如下：

以章节标题（#级）作为主题，章节子标题（##级）作为问题的基础。

问题格式为：“问题：xxx”，答案格式为：“答案：xxx”。

答案需包含子标题下的所有内容（包括列表、加粗等Markdown语法），保持内容完整性和可读性。

如果内容中有总结性语句（如加粗或强调部分），需保留在答案中。
示例输入：
```markdown
# RTOS  

## 内核态，用户态的区别  
区别：运行级别，是否可以操作硬件  
用户态->内核态：系统调用、异常、外围设备中断  
```
示例输出：
问题：内核态，用户态的区别
答案：区别：运行级别，是否可以操作硬件。用户态->内核态：系统调用、异常、外围设备中断。
```

### API调用指南
其中api调用的指南如下：
**请求：**
```python
import queue
import sys
from datetime import datetime
from multiprocessing.pool import ThreadPool

from volcenginesdkarkruntime import Ark


def worker(
    worker_id: int,
    client: Ark,
    requests: queue.Queue[dict],
):
    print(f"Worker {worker_id} is starting.")

    while True:
        request = requests.get()

        # check for signal of no more request
        if not request:
            # put back on the queue for other workers
            requests.put(request)
            return

        try:
            # do request
            completion = client.batch_chat.completions.create(**request)
            print(completion)
        except Exception as e:
            print(e, file=sys.stderr)
        finally:
            requests.task_done()

def main():
    start = datetime.now()
    max_concurrent_tasks, task_num = 1000, 10000

    requests = queue.Queue()
    client = Ark(api_key="YOUR_API_KEY", timeout=24 * 3600)

    # mock `task_num` tasks
    for _ in range(task_num):
        requests.put(
            {
                "model": "ep-bi-20250519092945-bskj6",
                "messages": [
                    {
                        "role": "system",
                        "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手",
                    },
                    {"role": "user", "content": "常见的十字花科植物有哪些？"},
                ],
            }
        )

    # put a signal of no more request
    requests.put(None)

    # create `max_concurrent_tasks` workers and start them
    with ThreadPool(max_concurrent_tasks) as pool:
        for i in range(max_concurrent_tasks):
            pool.apply_async(worker, args=(i, client, requests))
        pool.apply_async(worker, args=(i, client, requests))

        # wait for all request to done
        pool.close()
        pool.join()

    client.close()

    end = datetime.now()
    print(f"Total time: {end - start}, Total task: {task_num}")

if __name__ == "__main__":
    main()

```
**回应：**
```json
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "Hello! How can I help you today?",
        "role": "assistant"
      }
    }
  ],
  "created": 1742631811,
  "id": "0217426318107460cfa43dc3f3683b1de1c09624ff49085a456ac",
  "model": "doubao-1-5-pro-32k-250115",
  "service_tier": "default",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 9,
    "prompt_tokens": 19,
    "total_tokens": 28,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0
    }
  }
}
```

# 测试 
设计对应的测试用例，测试代码